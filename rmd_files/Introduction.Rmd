---
output:
  pdf_document: default
  word_document: default
  html_document: default
---
## INTRODUCTION
Archaeologists often use data and quantitative statistical methods to evaluate their ideas. Although there are various statistical frameworks for decision-making in archaeology and science in general, in this chapter, we provide a simple explanation of Bayesian statistics. To contextualize the Bayesian statistical framework, we briefly compare it to the more widespread null hypothesis significance testing (NHST) approach. We also provide a simple example to illustrate how archaeologists use data and the Bayesian framework to compare hypotheses and evaluate their uncertainty. We then review how archaeologists have applied Bayesian statistics to solve research problems related to radiocarbon dating and chronology, lithic, ceramic, zooarchaeological, bioarchaeological, and spatial analyses. Because recent work has reviewed Bayesian applications in archaeology from the 1990s up to 2017 [@buck_bayesian_1996; @buck_applications_2001; @otarola-castillo_bayesian_2018], this work considers the relevant literature published since 2017.

### Null hypothesis significance testing

Archaeologists use NHST to assess the extent to which well-observed material culture recovered from archaeological sites aligns with their hypotheses about past people. Statisticians pioneered the NHST inferential structure in the early twentieth century and, thanks to its success in research practice, it became widely available to scientists of the time [e.g., @fisher_statistical_1925; @neyman_problem_1933: 294]. In the 1950s, various science-oriented archaeological works introduced NHST methodology to the field [e.g., @myers_applications_1950; @spaulding_statistical_1953; @binford_consideration_1964; @clarke_analytical_1968]. Today, numerous textbooks continue to teach archaeological scientists introductory NHST statistical concepts such as confidence intervals and p-values [e.g., @fletcher_digging_2005; @carlson_quantitative_2017; @mccall_strategies_2018; @banning_archaeologists_2020]. 

Statistical methods that follow the NHST framework provide inference by estimating the parameters of a probability model used to represent the salient features of a population (e.g., the mean and variance). Scientists usually hypothesize the value of the population’s parameters—the so-called “null” hypothesis—and design experiments or observational studies to generate quantifiable data that can be used to test it. After observation, the data are compared to the null hypothesis’ assumptions using a probability measure known as the p-value. This comparative procedure first assumes a probability model for the underlying population, then evaluates whether the data collected are expected or probable outcomes of that population, and thus whether the null hypothesis is (plausibly) true. 

A large p-value, usually greater than 0.05, indicates that the data are not extreme and “fails to reject” the null hypothesis. By contrast, a small or “significant” p-value, usually less than 0.05, indicates that the data are extreme and have a low probability with respect to the assumptions stated in the null hypothesis. In this case, investigators may “reject the null hypothesis” in favour of an alternative hypothesis. In short, to arbitrate between hypotheses, NHST uses *the probability that the stated null hypothesis generated the data*. 

Although this approach is one of the most widely used inferential frameworks across the sciences, it has had its share of criticism [e.g., @gelman_multilevel_2006; @vidgen_p-values_2016; @gelman_failure_2018]. For example, statisticians have recently targeted p-values mainly for their arbitrariness and misuse [@wasserstein_moving_2019]. Although some mistake statistical significance for practical significance [e.g., @kramer_sibling_2016], the interpretation of significant p-values, in terms of rejecting the null hypothesis, is well understood. However, how to interpret non-significant p-values is less clear. Similarly, the NHST toolkit does not include acceptance of a null hypothesis. Nevertheless, some misunderstand this point and attempt to use NHST to verify their null hypotheses. 

Language appears to be part of the problem here, but failing to reject a null hypothesis is not synonymous with accepting it. Instead, “failing to reject” means that there is not enough evidence to invalidate the null hypothesis. Moreover, the relationship between probabilities and alternative hypotheses is not clear and is often misunderstood [@benjamin_three_2019]. In particular, it is challenging to evaluate multiple alternative hypotheses within the NHST framework. Indeed, the ability to assign probabilities to multiple hypotheses in light of the data is one of the many reasons researchers have turned to Bayesian statistics.


## BAYESIAN STATISTICS

During the late twentieth century, scientists popularized Bayesian inference, a statistical approach based on developments made in the eighteenth century by Reverend Thomas @bayes_essay_1763. Bayes was an English Presbyterian minister and mathematician who solved problems in probability involving conditional and prior probabilities [@bellhouse_reverend_2004]. Soon after the popularization of Bayesian inference in the sciences, archaeologists also incorporated Bayesian methods into their toolkits to evaluate hypotheses [e.g., @buck_bayesian_1996]. Today, Bayesian methods have proliferated throughout the scientific literature, including in anthropological and archaeological science [@gelman_bayesian_2020; @otarola-castillo_bayesian_2018; @mcelreath_statistical_2020]. In the past, feasible execution of Bayesian methods was difficult because some calculations are intractable and require intensive computation. Today’s powerful personal computers and high-speed Markov Chain Monte Carlo (MCMC) algorithms, such as the Metropolis-Hastings, Gibbs, and Hamiltonian procedures, have helped to overcome this obstacle and further popularize the approach [e.g., @howson_scientific_2006 :xi; @robert_short_2011; @dunson_hastings_2020].

Another reason for Bayesian approaches’ increased popularity might be the simplicity of interpreting probabilities compared to the p-values used in NHST [@otarola-castillo_bayesian_2018]. Scientists apply Bayesian inference to compute the probability of a hypothesis directly and thus obtain clearer and more direct interpretations than those available from NHST. Also, as with NHST, the degree to which the given hypothesis supports the data is computed, usually via an explicit probability model, known as a likelihood. We formally define these terms below, but in summary, **the likelihood** is a statistical function whose form is determined by the specific probability model we are using. Crucially, Bayesian inference enables researchers to incorporate their expert (or prior) knowledge about the hypothesis into the statistical analysis. Experts’ **prior** knowledge in a field can be quite valuable; however, it is not often operationalized. Practitioners of Bayesian inference convert prior knowledge into **prior probabilities** and use them as part of statistical analyses. Once the prior probability has been determined, as with NHST, new data are observed to test the hypothesis. The likelihood is combined with (or weighted by) the prior to give the **Bayesian posterior distribution**. From this, the probability of the hypothesis given the observed data and the prior knowledge can be computed [@buck_bayesian_1996]. These steps, including the formalization of a simple prior probability, likelihood, and computation of the posterior will be exemplified below in a simple archaeological example.

The primary advantage of Bayesian statistics over NHST is the clarity of the inferences drawn from the analysis. Furthermore, by formally including previous experience or expert information, prior probabilities offer practical improvements over NHST, typically reducing uncertainty in the conclusions reached [@cowgill_past_2001]. Including prior knowledge produces a comprehensive understanding of the proposed hypothesis’ relevance to a larger body of knowledge. Moreover, incorporating prior probabilities enables Bayesian inferences to be “updated,” creating a cyclical effect as current knowledge becomes prior knowledge for future studies. Perhaps Dennis @lindley_bayesian_1972 best summarized the Bayesian learning process by writing the aphorism “today’s posterior is tomorrow’s prior”. Helpfully, it is also possible to use what is known as a flat, vague, or uninformative prior (as we do in our example below) in situations where little or no expert prior knowledge is available, but one may wish to take advantage of the other features of the Bayesian framework.

To further contextualize the application of Bayesian statistics, we provide an example that illustrates how one can use Bayesian statistics to select a hypothesis and solve an archaeological research problem. The example demonstrates how archaeologists can make probabilistic inferences using data and simple prior information about a hypothesis, how to evaluate the uncertainty surrounding a hypothesis, why this approach seems less ambiguous than NHST, and thus why it is becoming increasingly popular. We also formally define the Bayesian framework and review recent Bayesian statistics applications in the archaeological literature.

